{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "This notebook shows to build a Naive Bayes classifier from scratch. We will first look into features only contian binary values, and later we will also implement Gaussian Naive Bayes for more discrete features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes with binary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    '''X binary cases, y could be multiclasses\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''Initialze some variables'''\n",
    "        self.priors = []\n",
    "        self.condi = []\n",
    "        self.counts = None\n",
    "        self.label_names = None\n",
    "    def get_classes(self, labels):\n",
    "        '''Count each class, and store the name of each class'''\n",
    "        self.counts = Counter(labels)\n",
    "        self.label_names = list(self.counts.keys())\n",
    "    def get_prior(self, labels):\n",
    "        '''Calculate the prior probability of each class'''\n",
    "        for name in self.label_names:\n",
    "            self.priors.append(self.counts[name]/len(labels))\n",
    "    def get_conditional(self, training, labels):\n",
    "        '''Get conditional probability of features given label'''\n",
    "        for label_name in self.label_names:\n",
    "            pos = np.where(labels == label_name)[0]\n",
    "            # here we include a prior probability.\n",
    "            # for any features we did not in the training set\n",
    "            # we assume it has the probability of 1/(# of classes)\n",
    "            self.condi.append((np.sum(training[pos, :], axis = 0)+1)/(len(pos)+len(self.label_names)))\n",
    "    def train(self, training, labels):\n",
    "        '''Train dataset'''\n",
    "        labels = labels.ravel()\n",
    "        self.get_classes(labels)\n",
    "        self.get_prior(labels)\n",
    "        self.get_conditional(training, labels)\n",
    "    def predict(self, testset):\n",
    "        '''Predict given input dataset\n",
    "        Return:\n",
    "            list of classes\n",
    "        '''\n",
    "        if scipy.sparse.issparse(testset):\n",
    "            testset = testset.todense()\n",
    "        results = []\n",
    "        for test in testset:\n",
    "            best = None\n",
    "            for i in range(len(self.label_names)):\n",
    "                joint_prob = np.multiply(test, self.condi[i])+np.multiply(1-test, 1-self.condi[i])\n",
    "                log_jprob = np.sum(np.log(joint_prob))+np.log(self.priors[i])\n",
    "                if best is None or best < log_jprob:\n",
    "                    best = log_jprob\n",
    "                    index = i\n",
    "            results.append(self.label_names[index])\n",
    "        return results\n",
    "    @staticmethod\n",
    "    def accuracy(predicts, labels):\n",
    "        '''\n",
    "        Return:\n",
    "            float, accuracy of prediction\n",
    "        '''\n",
    "        return sum(predicts == labels.ravel())/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test how this one works\n",
    "The data is from [CMU's ML course 10-601](http://www.cs.cmu.edu/~ninamf/courses/601sp15/hw/hw3_code.tar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'XTrain', 'XTest', 'XTrainSmall', 'yTrain', 'yTest', 'yTrainSmall', 'Vocabulary'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict = sio.loadmat('./hw3/HW3Data.mat')\n",
    "var_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = NaiveBayes()\n",
    "\n",
    "NB.train(var_dict['XTrain'], var_dict['yTrain'])\n",
    "pred_train = NB.predict(var_dict['XTrain'])\n",
    "NB.accuracy(pred_train, var_dict['yTrain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793103448275862"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = NB.predict(var_dict['XTest'])\n",
    "NB.accuracy(results, var_dict['yTest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
